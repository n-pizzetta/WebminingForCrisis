{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    \"\"\"Remove URLs from a text string.\"\"\"\n",
    "    \n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "def load_tweets():\n",
    "    \"\"\"Load tweet texts from the specified JSON file, remove stopwords & URLs, return a list of cleaned tweets.\"\"\"\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tweets = []\n",
    "    \n",
    "    with open(\"DATASET-20250325/database/Nodes/Tweet.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                tweet_json = json.loads(line)\n",
    "                props = tweet_json['n']['properties']\n",
    "                text = props.get(\"text\", \"\")\n",
    "                \n",
    "                # Remove URLs\n",
    "                text = remove_urls(text)\n",
    "                \n",
    "                # Basic cleaning\n",
    "                if text.strip():\n",
    "                    # Tokenize\n",
    "                    words = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "                    # Remove stopwords\n",
    "                    filtered_words = [word for word in words if word not in stop_words]\n",
    "                    # Rejoin\n",
    "                    filtered_text = \" \".join(filtered_words)\n",
    "                    \n",
    "                    # Append cleaned tweet text to the list\n",
    "                    tweets.append(filtered_text)\n",
    "            \n",
    "            except Exception:\n",
    "                # If there's any parse or JSON error, just skip that line\n",
    "                continue\n",
    "    \n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = load_tweets_with_event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colorado told amazing',\n",
       " 'rt northfortynews tanker helicopter heads paradise park drop water highparkfire']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "tweet_vectors = vectorizer.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a function to vectorize the query\n",
    "def vectorize_query(query_keywords, vectorizer):\n",
    "    query_str = \" \".join(query_keywords)\n",
    "    query_vec = vectorizer.transform([query_str])\n",
    "    return query_vec\n",
    "\n",
    "# Step 3: Define a function to get top-k tweets\n",
    "def get_top_k_tweets(query_keywords, vectorizer, tweet_vectors, tweets, k=3):\n",
    "    query_vec = vectorize_query(query_keywords, vectorizer)\n",
    "    similarities = cosine_similarity(query_vec, tweet_vectors).flatten()\n",
    "    top_k_indices = similarities.argsort()[::-1][:k]\n",
    "    results = [(tweets[idx], similarities[idx]) for idx in top_k_indices]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWEET: shooting downtown dallas (score=0.5367)\n",
      "TWEET: explosion texas (score=0.4905)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query_keywords = [\"explosion\", \"downtown\"]\n",
    "top_tweets = get_top_k_tweets(query_keywords, vectorizer, tweet_vectors, tweets, k=2)\n",
    "\n",
    "for tweet, score in top_tweets:\n",
    "    print(f\"TWEET: {tweet} (score={score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building toy examples : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_queries = [\n",
    "    {\n",
    "        \"query_keywords\": [\"explosion\", \"downtown\"],\n",
    "        \"description\": \"Search for tweets about explosions in downtown areas\",\n",
    "    },\n",
    "    {\n",
    "        \"query_keywords\": [\"movie\", \"box\", \"office\"],\n",
    "        \"description\": \"Search for tweets referencing box office and movies\",\n",
    "    },\n",
    "    {\n",
    "        \"query_keywords\": [\"football\", \"match\"],\n",
    "        \"description\": \"Search for tweets about football matches\",\n",
    "    },\n",
    "    {\n",
    "        \"query_keywords\": [\"AI\", \"tech\", \"conference\"],\n",
    "        \"description\": \"Search for tweets about AI conferences\",\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Query: ['explosion', 'downtown'] - Search for tweets about explosions in downtown areas\n",
      "  -> shooting downtown dallas (score=0.5367)\n",
      "  -> explosion texas (score=0.4905)\n",
      "  -> shooting downtown dallas protest yikes downtown dallas (score=0.4580)\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Query: ['movie', 'box', 'office'] - Search for tweets referencing box office and movies\n",
      "  -> movie watch walangpasok (score=0.4329)\n",
      "  -> ramaphosa always sounds like movie president money (score=0.2873)\n",
      "  -> hurricane ready office fridayfeeling florence office landfall nc (score=0.2799)\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Query: ['football', 'match'] - Search for tweets about football matches\n",
      "  -> match donation (score=0.5423)\n",
      "  -> 2 explosions heard paris stadium france germany football match via ap (score=0.5204)\n",
      "  -> rt gmanews 2 explosions heard paris stadium france germany football match via ap (score=0.4852)\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Query: ['AI', 'tech', 'conference'] - Search for tweets about AI conferences\n",
      "  -> online volunteers map philippines typhoon tech (score=0.3135)\n",
      "  -> poway synagogue shooting news conference (score=0.3061)\n",
      "  -> day 1937 nepal tech helping (score=0.2919)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for q in toy_queries:\n",
    "    print(40*\"-\")\n",
    "    print(f\"Query: {q['query_keywords']} - {q['description']}\")\n",
    "    results = get_top_k_tweets(q['query_keywords'], vectorizer, tweet_vectors, tweets, k=3)\n",
    "    for tweet, score in results:\n",
    "        print(f\"  -> {tweet} (score={score:.4f})\")\n",
    "    print(40*\"-\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
